{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERTUBIAArticleTBS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOP/TxXT0q4k/oPyQ6BvrtV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salmenhsairi/EndOfStudiesProjectNotebooks/blob/main/BERTUBIAArticleTBS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mounting Drive FS"
      ],
      "metadata": {
        "id": "Heceb4mM27Dc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZ4RYa1DOL2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d183ba6d-b243-45bf-8b2a-0aa0b486eee9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pulling `UBIAI`'s necessary assets for a training demo"
      ],
      "metadata": {
        "id": "bR76DIvx3Hii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -r Fine_tune_BERT_with_spacy3\n",
        "! git clone https://github.com/UBIAI/Fine_tune_BERT_with_spacy3.git"
      ],
      "metadata": {
        "id": "B2hAGEItOYuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing dependencies \n",
        "* make sure you restart runtime to apply some settings changes"
      ],
      "metadata": {
        "id": "qM8sxJn83Udb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U pip setuptools wheel\n",
        "! pip install 'spacy[transformers]'\n",
        "# ! python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "id": "63Ae-zJvPEKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing the Data for the Model"
      ],
      "metadata": {
        "id": "seawtBzL4Pmr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert tsv files to JSON format  "
      ],
      "metadata": {
        "id": "LDgU-7Lo3fGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy convert Fine_tune_BERT_with_spacy3/train.tsv ./ -t json -n 1 -c iob\n",
        "!python -m spacy convert Fine_tune_BERT_with_spacy3/test.tsv ./ -t json -n 1 -c iob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfI-kBcSPTbR",
        "outputId": "0fe8744d-2e43-4bda-c830-e8437c76f246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;3m⚠ Document delimiters found, automatic document segmentation with `-n`\n",
            "disabled.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (1 documents): train.json\u001b[0m\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;3m⚠ Document delimiters found, automatic document segmentation with `-n`\n",
            "disabled.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (1 documents): test.json\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert JSON files To Spacy Binary format"
      ],
      "metadata": {
        "id": "Ueon5uYQ3-qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create on if doesn't exist\n",
        "! mkdir drive/MyDrive/NER_data"
      ],
      "metadata": {
        "id": "axgHKaZdGjTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert them to spacy binary file\n",
        "!python -m spacy convert train.json \"/content/drive/MyDrive/NER_data/\" -t spacy\n",
        "!python -m spacy convert test.json \"/content/drive/MyDrive/NER_data/\" -t spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtggt5nGQyWh",
        "outputId": "579c93bb-28d8-4eec-beff-ef77d5f4f123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Generated output file (77 documents):\n",
            "/content/drive/MyDrive/NER_data/train.spacy\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (11 documents):\n",
            "/content/drive/MyDrive/NER_data/test.spacy\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fill the remaining config defaults"
      ],
      "metadata": {
        "id": "FR3hSHoY4giC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fill config file for the ner model from the base config\n",
        "! python -m spacy init fill-config Fine_tune_BERT_with_spacy3/base_config.cfg spacy_config_origin.cfg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzeinT5Q-9qu",
        "outputId": "8bd22e6f-66af-42c3-b604-f837daaf607f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "spacy_config_origin.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train spacy_config_origin.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional : debugging new config file\n",
        "! python -m spacy debug data spacy_config_origin.cfg"
      ],
      "metadata": {
        "id": "QWQMmRAV_iNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check whether  the gpu is accessible for spacy\n",
        "import spacy\n",
        "spacy.require_gpu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB5ycqGTcNfl",
        "outputId": "f401d02c-9054-416f-900b-15b97d3c0a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train \\\n",
        "/content/spacy_config_origin.cfg \\\n",
        "--gpu-id 0 \\\n",
        "--training.max_epochs 20 \\\n",
        "--components.transformer.max_batch_items=2048 \\\n",
        "--training.patience=500 \\\n",
        "--training.eval_frequency=50 \\\n",
        "--training.batcher.size=1000 \\\n",
        "--training.logger.progress_bar='true' \\\n",
        "--output='./'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgZkj0dL_tul",
        "outputId": "e00875bd-3191-4eb7-c5ea-f4fcfa632ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Saving to output directory: .\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-07-07 16:47:29,874] [INFO] Set up nlp object from config\n",
            "[2022-07-07 16:47:29,884] [INFO] Pipeline: ['transformer', 'ner']\n",
            "[2022-07-07 16:47:29,889] [INFO] Created vocabulary\n",
            "[2022-07-07 16:47:29,890] [INFO] Finished initializing nlp object\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2022-07-07 16:47:45,926] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0         360.05    488.73   15.74    9.38   48.96    0.16\n",
            "  3      50       74312.65  29757.83    4.03   72.73    2.07    0.04\n",
            "  6     100       34459.13   8207.06   51.48   53.65   49.48    0.51\n",
            " 10     150        3728.37   4228.92   53.31   70.82   42.75    0.53\n",
            " 13     200        2320.69   2555.89   63.16   65.92   60.62    0.63\n",
            " 16     250        1552.64   1551.94   62.90   59.81   66.32    0.63\n",
            "Epoch 17:  98% 49/50 [03:31<00:04,  4.37s/it]\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the pipeline after training"
      ],
      "metadata": {
        "id": "oo0yz-OH5Rz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.cli.evaluate import evaluate\n",
        "result = evaluate(\n",
        "    'model-best',\n",
        "    '/content/drive/MyDrive/NER_data/test.spacy',\n",
        "    output='/content/metrics.json',\n",
        "    use_gpu=-1,\n",
        ")"
      ],
      "metadata": {
        "id": "071VaXA4iq0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9WCokQAjY85",
        "outputId": "ecc174e3-2a80-4269-bee5-1680f72e899a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ents_f': 0.6315789473684211,\n",
              " 'ents_p': 0.6591549295774648,\n",
              " 'ents_per_type': {'DIPLOMA': {'f': 0.8387096774193549,\n",
              "   'p': 0.8125,\n",
              "   'r': 0.8666666666666667},\n",
              "  'DIPLOMA_MAJOR': {'f': 0.7887323943661971,\n",
              "   'p': 0.8,\n",
              "   'r': 0.7777777777777778},\n",
              "  'EXPERIENCE': {'f': 0.8333333333333334, 'p': 0.9375, 'r': 0.75},\n",
              "  'SKILLS': {'f': 0.5903814262023217,\n",
              "   'p': 0.6180555555555556,\n",
              "   'r': 0.5650793650793651}},\n",
              " 'ents_r': 0.6062176165803109,\n",
              " 'speed': 6048.513434116675,\n",
              " 'token_acc': 1.0,\n",
              " 'token_f': 1.0,\n",
              " 'token_p': 1.0,\n",
              " 'token_r': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## get model inference result with unseen data"
      ],
      "metadata": {
        "id": "d6CS1zb05Xxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"./model-best\")\n",
        "text = [\n",
        "'''Qualifications\n",
        "- A thorough understanding of C# and .NET Core\n",
        "- Knowledge of good database design and usage\n",
        "- An understanding of NoSQL principles\n",
        "- Excellent problem solving and critical thinking skills\n",
        "- Curious about new technologies\n",
        "- Experience building cloud hosted, scalable web services\n",
        "- Azure experience is a plus\n",
        "Requirements\n",
        "- Bachelor's degree in Computer Science or related field\n",
        "(Equivalent experience can substitute for earned educational qualifications)\n",
        "- Minimum 4 years experience with C# and .NET\n",
        "- Minimum 4 years overall experience in developing commercial software\n",
        "'''\n",
        "]\n",
        "for doc in nlp.pipe(text, disable=[\"tagger\", \"parser\"]):\n",
        "    print([(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUI8-_cmH8xy",
        "outputId": "16c804b2-cc19-4ba6-d9b9-79744a8d3d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('C', 'SKILLS'), ('#', 'SKILLS'), ('.NET', 'SKILLS'), ('database design', 'SKILLS'), ('usage', 'SKILLS'), ('NoSQL principles', 'SKILLS'), ('problem solving', 'SKILLS'), ('critical thinking', 'SKILLS'), ('building cloud hosted', 'SKILLS'), ('web services', 'SKILLS'), ('Azure experience', 'SKILLS'), ('Bachelor', 'DIPLOMA'), (\"'s\", 'DIPLOMA'), ('Computer Science', 'DIPLOMA_MAJOR'), ('4 years', 'EXPERIENCE'), ('C', 'SKILLS'), ('#', 'SKILLS'), ('.NET', 'SKILLS'), ('4 years', 'EXPERIENCE'), ('developing commercial software', 'SKILLS')]\n"
          ]
        }
      ]
    }
  ]
}