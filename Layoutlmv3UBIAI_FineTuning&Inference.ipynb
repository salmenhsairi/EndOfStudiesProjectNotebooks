{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salmenhsairi/EndOfStudiesProjectNotebooks/blob/main/Layoutlmv3UBIAI_FineTuning%26Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbPrhpvsnMbb"
      },
      "source": [
        "## Mount drive fs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udottwTEmRhF",
        "outputId": "983e4f2c-4a50-4696-cae2-1249b10dc42f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfAQB77cnLfh"
      },
      "source": [
        "## Installing requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c2rynmanL2y",
        "outputId": "52276b27-e0e6-4dad-8a31-b8e26079b037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 86 kB 2.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 27.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 67.9 MB/s \n",
            "\u001b[?25h  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 346 kB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 63.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 65.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 62.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 86 kB 7.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 59.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 71.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 69.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 72.9 MB/s \n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "! pip install -q git+https://github.com/huggingface/transformers.git\n",
        "! pip install -q git+https://github.com/huggingface/datasets.git \"dill<0.3.5\" seqeval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpb9Df-XnZCZ"
      },
      "source": [
        "## Pulling preprocessing file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Tv1cRSLnTyh",
        "outputId": "a35f3456-4ef6-4d98-c696-b379cbb25d8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'layoutlmv3FineTuning': No such file or directory\n",
            "Cloning into 'layoutlmv3FineTuning'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 16 (delta 3), reused 3 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n"
          ]
        }
      ],
      "source": [
        "! rm -r layoutlmv3FineTuning\n",
        "! git clone -b master https://github.com/salmenhsairi/layoutlmv3FineTuning.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L0nDhP-nl_q"
      },
      "source": [
        "## Loading UBIAI dataset from Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQnYjbS8nnXz",
        "outputId": "aca88940-4915-471c-a5d8-3e08ff72800d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'data': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "#!/bin/bash\n",
        "IOB_DATA_PATH = \"/content/drive/MyDrive/NERDatasets/OCR_Invoice_Extraction_Tp4PlPQ.zip\"\n",
        "# IOB_DATA_PATH = \"/content/drive/MyDrive/NERDatasets/EPIC_Case_Times_Extraction_ddvqdMl.zip\"\n",
        "! cd /content/\n",
        "! rm -r data\n",
        "! mkdir data\n",
        "! cp \"$IOB_DATA_PATH\" data/dataset.zip \n",
        "! cd data && unzip -q dataset && rm dataset.zip\n",
        "! cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cn8X5s4n8t5"
      },
      "source": [
        "## defining preprocessing params and running the script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "T_-H4goBn-F7"
      },
      "outputs": [],
      "source": [
        "#!/bin/bash\n",
        "#preprocessing args\n",
        "TEST_SIZE = 0.2\n",
        "DATA_OUTPUT_PATH = \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vBFmQ4hoD2p",
        "outputId": "36e1dd82-25b1-4450-8dcc-1a10096ac8d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% 1/1 [00:02<00:00,  2.17s/ba]\n",
            "Downloading: 100% 275/275 [00:00<00:00, 391kB/s]\n",
            "Downloading: 100% 1.12k/1.12k [00:00<00:00, 1.45MB/s]\n",
            "Downloading: 100% 856/856 [00:00<00:00, 1.27MB/s]\n",
            "Downloading: 100% 878k/878k [00:00<00:00, 7.67MB/s]\n",
            "Downloading: 100% 446k/446k [00:00<00:00, 5.82MB/s]\n",
            "100% 1/1 [00:03<00:00,  3.01s/ba]\n",
            "100% 1/1 [00:00<00:00,  1.21ba/s]\n",
            "Flattening the indices: 100% 1/1 [00:00<00:00, 20.65ba/s]\n",
            "Flattening the indices: 100% 1/1 [00:00<00:00, 83.11ba/s]\n"
          ]
        }
      ],
      "source": [
        "! python3 layoutlmv3FineTuning/preprocess.py --valid_size $TEST_SIZE --output_path $DATA_OUTPUT_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hBZo3FhoUEJ"
      },
      "source": [
        "## Proceed with Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xzJbXg4gpM3B"
      },
      "outputs": [],
      "source": [
        "from datasets import load_metric\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import LayoutLMv3ForTokenClassification,AutoProcessor\n",
        "from transformers.data.data_collator import default_data_collator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bU75MUSsohIb"
      },
      "outputs": [],
      "source": [
        "# load datasets\n",
        "from datasets import load_from_disk\n",
        "train_dataset = load_from_disk(f'/content/train_split')\n",
        "eval_dataset = load_from_disk(f'/content/eval_split')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WEDj23OQHjlR"
      },
      "outputs": [],
      "source": [
        "labels = train_dataset.features[\"labels\"].feature.names\n",
        "num_labels = len(labels)\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = i\n",
        "    id2label[i] = label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RptozkCioxhB"
      },
      "outputs": [],
      "source": [
        "metric = load_metric(\"seqeval\")\n",
        "import numpy as np\n",
        "\n",
        "return_entity_level_metrics = False\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels,zero_division='0')\n",
        "    if return_entity_level_metrics:\n",
        "        # Unpack nested dictionaries\n",
        "        final_results = {}\n",
        "        for key, value in results.items():\n",
        "            if isinstance(value, dict):\n",
        "                for n, v in value.items():\n",
        "                    final_results[f\"{key}_{n}\"] = v\n",
        "            else:\n",
        "                final_results[key] = value\n",
        "        return final_results\n",
        "    else:\n",
        "        return {\n",
        "            \"precision\": results[\"overall_precision\"],\n",
        "            \"recall\": results[\"overall_recall\"],\n",
        "            \"f1\": results[\"overall_f1\"],\n",
        "            \"accuracy\": results[\"overall_accuracy\"],\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VxWc2tGo8R4"
      },
      "source": [
        "## loading model and preprocessor (also required for Hugging face trainer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLcWS0BrpCp0",
        "outputId": "e46d5673-921d-4ea9-b7de-8eb82cc2bc7f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of LayoutLMv3ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "label_list = train_dataset.features[\"labels\"].feature.names\n",
        "num_labels = len(label_list)\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(label_list):\n",
        "    label2id[label] = i\n",
        "    id2label[i] = label\n",
        "\n",
        "model = LayoutLMv3ForTokenClassification.from_pretrained(\"microsoft/layoutlmv3-base\",\n",
        "                                                         id2label=id2label,\n",
        "                                                         label2id=label2id)\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmqcO0gJpSD5"
      },
      "source": [
        "## let's train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VNYR31ydPMic"
      },
      "outputs": [],
      "source": [
        "NUM_TRAIN_EPOCHS = 6 \n",
        "PER_DEVICE_TRAIN_BATCH_SIZE = 1\n",
        "PER_DEVICE_EVAL_BATCH_SIZE = 1\n",
        "LEARNING_RATE = 4e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iInYrU6DpD5p"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(output_dir=\"test\",\n",
        "                                  max_steps=1500,\n",
        "                                  # num_train_epochs=NUM_TRAIN_EPOCHS,\n",
        "                                  logging_strategy=\"epoch\",\n",
        "                                  save_total_limit=1,\n",
        "                                  per_device_train_batch_size=PER_DEVICE_TRAIN_BATCH_SIZE,\n",
        "                                  per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH_SIZE,\n",
        "                                  learning_rate=LEARNING_RATE,\n",
        "                                  evaluation_strategy=\"epoch\",\n",
        "                                  save_strategy=\"epoch\",\n",
        "                                  # eval_steps=100,\n",
        "                                  load_best_model_at_end=True,\n",
        "                                  metric_for_best_model=\"f1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O0rFEiBrGpQ",
        "outputId": "b7686886-5593-4c0d-c276-0beb442b9bb4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ],
      "source": [
        "# Initialize our Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=processor,\n",
        "    data_collator=default_data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JUL9WBIopT3J",
        "outputId": "07bdce46-ae98-47db-83aa-e85a90e6446d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='476' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 476/1500 03:29 < 07:32, 2.26 it/s, Epoch 11.88/38]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.131600</td>\n",
              "      <td>0.770097</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.886818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.686600</td>\n",
              "      <td>0.735390</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.886818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.619900</td>\n",
              "      <td>0.666163</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.886818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.543000</td>\n",
              "      <td>0.614050</td>\n",
              "      <td>0.281250</td>\n",
              "      <td>0.092784</td>\n",
              "      <td>0.139535</td>\n",
              "      <td>0.889481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.463300</td>\n",
              "      <td>0.573233</td>\n",
              "      <td>0.228916</td>\n",
              "      <td>0.195876</td>\n",
              "      <td>0.211111</td>\n",
              "      <td>0.890812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.409500</td>\n",
              "      <td>0.497680</td>\n",
              "      <td>0.228261</td>\n",
              "      <td>0.216495</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.895473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.335000</td>\n",
              "      <td>0.500194</td>\n",
              "      <td>0.195312</td>\n",
              "      <td>0.257732</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.895473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.297600</td>\n",
              "      <td>0.475257</td>\n",
              "      <td>0.316239</td>\n",
              "      <td>0.381443</td>\n",
              "      <td>0.345794</td>\n",
              "      <td>0.910786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.251600</td>\n",
              "      <td>0.425416</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.536082</td>\n",
              "      <td>0.458150</td>\n",
              "      <td>0.922770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.225700</td>\n",
              "      <td>0.411927</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.597938</td>\n",
              "      <td>0.544601</td>\n",
              "      <td>0.935419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.185200</td>\n",
              "      <td>0.416505</td>\n",
              "      <td>0.530973</td>\n",
              "      <td>0.618557</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.932756</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 11\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test/checkpoint-200\n",
            "Configuration saved in test/checkpoint-200/config.json\n",
            "Model weights saved in test/checkpoint-200/pytorch_model.bin\n",
            "Feature extractor saved in test/checkpoint-200/preprocessor_config.json\n",
            "tokenizer config file saved in test/checkpoint-200/tokenizer_config.json\n",
            "Special tokens file saved in test/checkpoint-200/special_tokens_map.json\n",
            "Deleting older checkpoint [test/checkpoint-160] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py:811: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  \"The `device` argument is deprecated and will be removed in v5 of Transformers.\", FutureWarning\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 11\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test/checkpoint-240\n",
            "Configuration saved in test/checkpoint-240/config.json\n",
            "Model weights saved in test/checkpoint-240/pytorch_model.bin\n",
            "Feature extractor saved in test/checkpoint-240/preprocessor_config.json\n",
            "tokenizer config file saved in test/checkpoint-240/tokenizer_config.json\n",
            "Special tokens file saved in test/checkpoint-240/special_tokens_map.json\n",
            "Deleting older checkpoint [test/checkpoint-200] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py:811: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  \"The `device` argument is deprecated and will be removed in v5 of Transformers.\", FutureWarning\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 11\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test/checkpoint-280\n",
            "Configuration saved in test/checkpoint-280/config.json\n",
            "Model weights saved in test/checkpoint-280/pytorch_model.bin\n",
            "Feature extractor saved in test/checkpoint-280/preprocessor_config.json\n",
            "tokenizer config file saved in test/checkpoint-280/tokenizer_config.json\n",
            "Special tokens file saved in test/checkpoint-280/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py:811: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  \"The `device` argument is deprecated and will be removed in v5 of Transformers.\", FutureWarning\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 11\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test/checkpoint-320\n",
            "Configuration saved in test/checkpoint-320/config.json\n",
            "Model weights saved in test/checkpoint-320/pytorch_model.bin\n",
            "Feature extractor saved in test/checkpoint-320/preprocessor_config.json\n",
            "tokenizer config file saved in test/checkpoint-320/tokenizer_config.json\n",
            "Special tokens file saved in test/checkpoint-320/special_tokens_map.json\n",
            "Deleting older checkpoint [test/checkpoint-240] due to args.save_total_limit\n",
            "Deleting older checkpoint [test/checkpoint-280] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py:811: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  \"The `device` argument is deprecated and will be removed in v5 of Transformers.\", FutureWarning\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 11\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test/checkpoint-360\n",
            "Configuration saved in test/checkpoint-360/config.json\n",
            "Model weights saved in test/checkpoint-360/pytorch_model.bin\n",
            "Feature extractor saved in test/checkpoint-360/preprocessor_config.json\n",
            "tokenizer config file saved in test/checkpoint-360/tokenizer_config.json\n",
            "Special tokens file saved in test/checkpoint-360/special_tokens_map.json\n",
            "Deleting older checkpoint [test/checkpoint-320] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py:811: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  \"The `device` argument is deprecated and will be removed in v5 of Transformers.\", FutureWarning\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 11\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test/checkpoint-400\n",
            "Configuration saved in test/checkpoint-400/config.json\n",
            "Model weights saved in test/checkpoint-400/pytorch_model.bin\n",
            "Feature extractor saved in test/checkpoint-400/preprocessor_config.json\n",
            "tokenizer config file saved in test/checkpoint-400/tokenizer_config.json\n",
            "Special tokens file saved in test/checkpoint-400/special_tokens_map.json\n",
            "Deleting older checkpoint [test/checkpoint-360] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py:811: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  \"The `device` argument is deprecated and will be removed in v5 of Transformers.\", FutureWarning\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 11\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test/checkpoint-440\n",
            "Configuration saved in test/checkpoint-440/config.json\n",
            "Model weights saved in test/checkpoint-440/pytorch_model.bin\n",
            "Feature extractor saved in test/checkpoint-440/preprocessor_config.json\n",
            "tokenizer config file saved in test/checkpoint-440/tokenizer_config.json\n",
            "Special tokens file saved in test/checkpoint-440/special_tokens_map.json\n",
            "Deleting older checkpoint [test/checkpoint-400] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py:811: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  \"The `device` argument is deprecated and will be removed in v5 of Transformers.\", FutureWarning\n"
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBE4iLXtpVS5"
      },
      "source": [
        "evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "ecAkmRwWpXXp",
        "outputId": "576e9aa0-fe66-4772-8296-022413b33d87"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 80\n",
            "  Batch size = 1\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py:811: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  \"The `device` argument is deprecated and will be removed in v5 of Transformers.\", FutureWarning\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [80/80 00:08]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'epoch': 6.0,\n",
              " 'eval_accuracy': 0.9939814284076579,\n",
              " 'eval_f1': 0.849673202614379,\n",
              " 'eval_loss': 0.026033718138933182,\n",
              " 'eval_precision': 0.8158995815899581,\n",
              " 'eval_recall': 0.8863636363636364,\n",
              " 'eval_runtime': 8.7292,\n",
              " 'eval_samples_per_second': 9.165,\n",
              " 'eval_steps_per_second': 9.165}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FgqvqdspcMx"
      },
      "source": [
        "## save the model for upcoming fine-tuning/infrence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HySwXilhpePx",
        "outputId": "d1404b59-7873-4c43-ab67-de40bd75e571"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/Work/LayoutLMModel/AnesthesiaLayoutLMV3\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/Work/LayoutLMModel/AnesthesiaLayoutLMV3/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/Work/LayoutLMModel/AnesthesiaLayoutLMV3/pytorch_model.bin\n",
            "Feature extractor saved in /content/drive/MyDrive/Colab Notebooks/Work/LayoutLMModel/AnesthesiaLayoutLMV3/preprocessor_config.json\n",
            "tokenizer config file saved in /content/drive/MyDrive/Colab Notebooks/Work/LayoutLMModel/AnesthesiaLayoutLMV3/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Colab Notebooks/Work/LayoutLMModel/AnesthesiaLayoutLMV3/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "trainer.save_model('/content/drive/MyDrive/Colab Notebooks/Work/LayoutLMModel/AnesthesiaLayoutLMV3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKytSkC5B8Ka"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10316fQYB_dj"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model = LayoutLMv3ForTokenClassification.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/Work/LayoutLMModel/AnesthesiaLayoutLMV3\")\n",
        "# processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)\n",
        "# model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ6bgpZRC8xx",
        "outputId": "efc37b28-b8b4-4e25-c87b-2dcbd9bb26b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['id', 'tokens', 'bboxes', 'ner_tags', 'image'])\n"
          ]
        }
      ],
      "source": [
        "# choose an example from the eval set for inference (we can use a test set instead)\n",
        "dataset = load_from_disk(f'/content/raw_data')\n",
        "example = dataset[\"test\"][7]\n",
        "print(example.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_oktzKGCe9Y",
        "outputId": "96960e72-5c16-4949-807f-c3b1cc2d20bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_ids torch.Size([1, 512])\n",
            "attention_mask torch.Size([1, 512])\n",
            "bbox torch.Size([1, 512, 4])\n",
            "labels torch.Size([1, 512])\n",
            "pixel_values torch.Size([1, 3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "image = example[\"image\"]\n",
        "words = example[\"tokens\"]\n",
        "boxes = example[\"bboxes\"]\n",
        "word_labels = example[\"ner_tags\"]\n",
        "\n",
        "encoding = processor(image, words, boxes=boxes, word_labels=word_labels, return_tensors=\"pt\",truncation=True, padding=\"max_length\")\n",
        "for k,v in encoding.items():\n",
        "  # encoding[k] = v.to('cuda')\n",
        "  print(k,v.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLavDbCMC58R",
        "outputId": "5efb6246-3a97-4045-d2e0-42b954e34f5d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py:811: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  \"The `device` argument is deprecated and will be removed in v5 of Transformers.\", FutureWarning\n"
          ]
        }
      ],
      "source": [
        "# Next, we do a forward pass. We use torch.no_grad() as we don't require gradient computation.\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  outputs = model(**encoding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ylaBnOhDt64"
      },
      "outputs": [],
      "source": [
        "# The model outputs logits of shape (batch_size, seq_len, num_labels).\n",
        "logits = outputs.logits\n",
        "predictions = logits.argmax(-1).squeeze().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lw6CWgRkELMA"
      },
      "outputs": [],
      "source": [
        "# ground truth labels to compare predictions with  them\n",
        "labels = encoding.labels.squeeze().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CjvxdQ3Ecto"
      },
      "outputs": [],
      "source": [
        "def unnormalize_box(bbox, width, height):\n",
        "     return [\n",
        "         width * (bbox[0] / 1000),\n",
        "         height * (bbox[1] / 1000),\n",
        "         width * (bbox[2] / 1000),\n",
        "         height * (bbox[3] / 1000),\n",
        "     ]\n",
        "\n",
        "token_boxes = encoding.bbox.squeeze().tolist()\n",
        "width, height = image.size\n",
        "\n",
        "true_predictions = [model.config.id2label[pred] for pred, label in zip(predictions, labels) if label != - 100]\n",
        "true_labels = [model.config.id2label[label] for prediction, label in zip(predictions, labels) if label != -100]\n",
        "true_boxes = [unnormalize_box(box, width, height) for box, label in zip(token_boxes, labels) if label != -100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsyGXCWGEgey"
      },
      "outputs": [],
      "source": [
        "def random_color():\n",
        "  return np.random.randint(0,255,3)\n",
        "def iob_to_label(label):\n",
        "    label = label[2:]\n",
        "    if not label:\n",
        "      return 'other'\n",
        "    return label\n",
        "label2color = {f'{iob_to_label(label).lower()}':(random_color()[0],random_color()[1],random_color()[2]) for label in label2id.keys()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiBPZdlpEki4"
      },
      "source": [
        "check the inference result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "klsteBvpEmU5",
        "outputId": "cce28821-89d2-4901-8003-d23ac233c3f9"
      },
      "outputs": [],
      "source": [
        "from PIL import ImageDraw, ImageFont\n",
        "\n",
        "image = image.convert('RGBA')\n",
        "tmp = image.copy()\n",
        "# draw = ImageDraw.Draw(tmp)\n",
        "overlay = Image.new('RGBA', tmp.size,(0,0,0)+(0,))\n",
        "draw = ImageDraw.Draw(overlay)\n",
        "font = ImageFont.load_default()\n",
        "\n",
        "# label2color = {'question':'blue', 'answer':'green', 'header':'orange', 'other':'violet'}\n",
        "\n",
        "for prediction, box in zip(true_predictions, true_boxes):\n",
        "    predicted_label = iob_to_label(prediction).lower()\n",
        "    draw.rectangle(box, outline=label2color[predicted_label],width=3,fill=label2color[predicted_label]+(int(255*0.25),))\n",
        "    draw.text((box[0] + 10, box[1] - 10), text=predicted_label, fill=label2color[predicted_label],font=font)\n",
        "\n",
        "img = Image.alpha_composite(tmp, overlay)\n",
        "img = img.convert(\"RGB\")\n",
        "img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJyZqsehEqGX"
      },
      "source": [
        "compare with ground truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ji9IGhQtEsVH",
        "outputId": "07d7f6d3-f04d-449e-d33d-dc8a77cd5b0a"
      },
      "outputs": [],
      "source": [
        "image = example[\"image\"]\n",
        "image = image.convert('RGBA')\n",
        "tmp = image.copy()\n",
        "# draw = ImageDraw.Draw(tmp)\n",
        "overlay = Image.new('RGBA', tmp.size,(0,0,0)+(0,))\n",
        "draw = ImageDraw.Draw(overlay)\n",
        "font = ImageFont.load_default()\n",
        "\n",
        "for word, box, label in zip(example['tokens'], example['bboxes'], example['ner_tags']):\n",
        "  actual_label = iob_to_label(id2label[label]).lower()\n",
        "  box = unnormalize_box(box, width, height)\n",
        "  draw.rectangle(box, outline=label2color[actual_label],width=3,fill=label2color[actual_label]+(int(255*0.25),))\n",
        "  draw.text((box[0] + 10, box[1] - 10), text=actual_label, fill=label2color[actual_label],font=font)\n",
        "\n",
        "img = Image.alpha_composite(tmp, overlay)\n",
        "img = img.convert(\"RGB\")\n",
        "img"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "SbPrhpvsnMbb",
        "vfAQB77cnLfh",
        "gpb9Df-XnZCZ",
        "8hBZo3FhoUEJ",
        "9VxWc2tGo8R4",
        "gmqcO0gJpSD5",
        "_FgqvqdspcMx",
        "q3jWKsRcNIsl"
      ],
      "include_colab_link": true,
      "name": "Layoutlmv3UBIAI_FineTuning&Inference.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
